Revision: 912ec2e277a43973ff418176cbfd0885f09ea036
Patch-set: 5
File: liblog/logd_write.c

22:0-22:22
Fri Feb 13 16:46:09 2015 +0000
Author: Mark Salyzyn <1032276@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: cbd1e4e3_329b508c
Bytes: 145
Are we going to have build problems for simulator, host, or MAC builds? This may have to be #ifdef !FAKE_LOG_DEVICE if not universally available.

22:0-22:22
Fri Feb 13 16:57:54 2015 +0000
Author: Elliott Hughes <1003224@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: cbd1e4e3_329b508c
UUID: 0b4cdc89_e7c2bc29
Bytes: 218
dude, we removed the simulator years before you joined. i think it's okay to let it go :-)

[+danalbert] did a lot of work to make this work everywhere and in every combination of C and C++, and iirc there are no gaps.

313
Sat Feb 14 02:23:54 2015 +0000
Author: Wink Saville <1001401@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 2b40c074_3d648fad
Bytes: 75
All other errors (i.e. negative values of ret) will have written something?

313
Sat Feb 14 03:55:17 2015 +0000
Author: Mark Salyzyn <1032276@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 2b40c074_3d648fad
UUID: 4b6c1415_56c4d466
Bytes: 131
This is the _only_ error worth tracking, all others mean dysfunctional logd. If anything else happens, you are not getting through.

313
Sat Feb 14 15:21:01 2015 +0000
Author: Wink Saville <1001401@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 4b6c1415_56c4d466
UUID: 6b0c7878_2fc3c993
Bytes: 111
Hmmm, so doesn't that mean we dropped log output, and in which case we should handle those errors the same way?

313
Sat Feb 14 17:13:01 2015 +0000
Author: Mark Salyzyn <1032276@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 6b0c7878_2fc3c993
UUID: 2b69a006_98d3395f
Bytes: 2263
Ok, I will need to be clearer about my reasoning and will detail why and my architectural concerns. You may have forced my hand to consider adding a README or local comment to this source submission.

First off, the counter is a can not happen and meant to debug and notify about a structural issue. If it happens, the integrator/vendor/partner uses this as a signal to increase the value they tuned /proc/sys/net/unix/max_dgram_qlen; or realize they are producing spam or a Denial Of Service to the logging subsystem and take action to reduce it to a reasonable level. One missed log message is enough, and reason enough to take these mitigating actions. It is _not_ meant to aid triage by telling the developer there are missed message and let them ignore the underlying problem(s).

By sending the message from upstream we are taking advantage of a KISS design, but with the knowledge we are adding to the logging pressure when doing so by slipping the message through the very same log entry point that is prostrated.

Can not handle them the same way, the other errors occur when the logger is typically incapable of propagating them (eg: selinux MAC violations to the sockets, DAC permission to access the socket, logger crashing and forgetting the logs, logger stopped). The only one we can deal with is ENOTCONN, and it is handled above, and if it continues, means the logger is likely stopped. Once restarted, if we take generic action, the logger will get a flurry of lost message events from _all_ participants right at the _beginning_ of the log (a "duh, what did you think?"). That situation signals a complete truncation of the logs.

In the past, under many similar situations outlined above in other server projects, we already have a perfect storm, not contributing to it, and not producing messages that are meaningless to the logger data flow or result in an increase pressure on the logger unnecessarily.

This is all in the name of graceful failure modes. I have experienced dogpiles many times in my life, they often do not bode well for the developer and usually result in other engineers muttering about the heritage and experience of that developer ;-} lol

I will now consider how I can say this in a manner that is clear and concise ...

