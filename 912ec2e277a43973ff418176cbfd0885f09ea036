Revision: 912ec2e277a43973ff418176cbfd0885f09ea036
Patch-set: 5
File: liblog/logd_write.c

22:0-22:22
Fri Feb 13 16:46:09 2015 +0000
Author: Mark Salyzyn <1032276@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: cbd1e4e3_329b508c
Bytes: 145
Are we going to have build problems for simulator, host, or MAC builds? This may have to be #ifdef !FAKE_LOG_DEVICE if not universally available.

22:0-22:22
Fri Feb 13 16:57:54 2015 +0000
Author: Elliott Hughes <1003224@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: cbd1e4e3_329b508c
UUID: 0b4cdc89_e7c2bc29
Bytes: 218
dude, we removed the simulator years before you joined. i think it's okay to let it go :-)

[+danalbert] did a lot of work to make this work everywhere and in every combination of C and C++, and iirc there are no gaps.

313
Sat Feb 14 02:23:54 2015 +0000
Author: Wink Saville <1001401@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: 2b40c074_3d648fad
Bytes: 75
All other errors (i.e. negative values of ret) will have written something?

313
Sat Feb 14 03:55:17 2015 +0000
Author: Mark Salyzyn <1032276@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 2b40c074_3d648fad
UUID: 4b6c1415_56c4d466
Bytes: 131
This is the _only_ error worth tracking, all others mean dysfunctional logd. If anything else happens, you are not getting through.

313
Sat Feb 14 15:21:01 2015 +0000
Author: Wink Saville <1001401@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 4b6c1415_56c4d466
UUID: 6b0c7878_2fc3c993
Bytes: 111
Hmmm, so doesn't that mean we dropped log output, and in which case we should handle those errors the same way?

313
Sat Feb 14 17:13:01 2015 +0000
Author: Mark Salyzyn <1032276@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 6b0c7878_2fc3c993
UUID: 2b69a006_98d3395f
Bytes: 2263
Ok, I will need to be clearer about my reasoning and will detail why and my architectural concerns. You may have forced my hand to consider adding a README or local comment to this source submission.

First off, the counter is a can not happen and meant to debug and notify about a structural issue. If it happens, the integrator/vendor/partner uses this as a signal to increase the value they tuned /proc/sys/net/unix/max_dgram_qlen; or realize they are producing spam or a Denial Of Service to the logging subsystem and take action to reduce it to a reasonable level. One missed log message is enough, and reason enough to take these mitigating actions. It is _not_ meant to aid triage by telling the developer there are missed message and let them ignore the underlying problem(s).

By sending the message from upstream we are taking advantage of a KISS design, but with the knowledge we are adding to the logging pressure when doing so by slipping the message through the very same log entry point that is prostrated.

Can not handle them the same way, the other errors occur when the logger is typically incapable of propagating them (eg: selinux MAC violations to the sockets, DAC permission to access the socket, logger crashing and forgetting the logs, logger stopped). The only one we can deal with is ENOTCONN, and it is handled above, and if it continues, means the logger is likely stopped. Once restarted, if we take generic action, the logger will get a flurry of lost message events from _all_ participants right at the _beginning_ of the log (a "duh, what did you think?"). That situation signals a complete truncation of the logs.

In the past, under many similar situations outlined above in other server projects, we already have a perfect storm, not contributing to it, and not producing messages that are meaningless to the logger data flow or result in an increase pressure on the logger unnecessarily.

This is all in the name of graceful failure modes. I have experienced dogpiles many times in my life, they often do not bode well for the developer and usually result in other engineers muttering about the heritage and experience of that developer ;-} lol

I will now consider how I can say this in a manner that is clear and concise ...

313
Mon Feb 16 15:10:09 2015 +0000
Author: John Michelau <1005146@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 2b69a006_98d3395f
UUID: 8b20ccdf_08dfe7e1
Bytes: 801
Ok, perhaps my earlier comments can be ignored, then.  Please consider, though, that an OEM like ourselves that is downstream not only from AOSP, but also a chipset vendor, may receive a drop of software that is less than ideal, and still have to press forward with improving it functionally in many other subsystems in _parallel_ with investigating and fixing the performance issues causing the log drops.  At least from my end, having the drops reported in-band for each stream would likely increase the visibility and pressure for action to eliminate them.  We have monitoring in place for these drop messages now, wherever they reside, but once they appear there is still a time lag before they can be root-caused and fixed.  During that time, all other (triage) users potentially remain confused.

313
Mon Feb 23 16:28:41 2015 +0000
Author: Mark Salyzyn <1032276@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: 8b20ccdf_08dfe7e1
UUID: 8885328c_e0d4e2c4
Bytes: 71
I will think about a solution to this concern (as voiced in Patchset 2)

